\section{Capabilities}
\label{sec:capabilities}

Foundation models acquire capabilities, some that surprisingly emerge from their learning process, that power downstream applications (\refsec{applications}).
To reason about how the capabilities of foundation models influence the discussion of creating AI systems with certain fundamental capabilities.
Specifically, we discuss linguistic (\refsec{language}) and visual (\refsec{vision}) capabilities alongside the ability to affect the physical world (\refsec{robotics}), perform reasoning and search (\refsec{reasoning}), and interact with humans (\refsec{interaction}). 
In addition, we discuss how self-supervision (the technical approach used to learn most current foundation models) philosophically relates to the ability to understand (\refsec{philosophy}). 
 
\pl{highlight multi-modality here}

\pl{highlight generative modeling capabilities}

% Foundation models possess various \emph{capabilities} that applications can draw from.
% These capabilities include
% the ability to process different modalities (e.g., language, vision), affect
% the physical world (robotics), perform reasoning, and interact with
% humans (interaction).
%Note that each capability corresponds to an entire research community.
%We will describe the challenges in each field and how foundation models
%will transform it.

\input capabilities/language
\input capabilities/vision
\input capabilities/robotics
\input capabilities/reasoning
\input capabilities/interaction
\input capabilities/philosophy
